{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Zm-FacEO770S"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv"
      ],
      "metadata": {
        "id": "VvqUeJfC9pf7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tweet-preprocessor\n",
        "# https://github.com/s/preprocessor\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LU-qcQ0o0CeY",
        "outputId": "a4465f28-61df-4b25-b529-a50299afae77"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tweet-preprocessor\n",
            "  Downloading tweet_preprocessor-0.6.0-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: tweet-preprocessor\n",
            "Successfully installed tweet-preprocessor-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#before covid\n",
        "data = pd.read_csv('raw_partner_headlines.csv')"
      ],
      "metadata": {
        "id": "wReAWM0p7-jM"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FitEJe_U8t9M",
        "outputId": "c14a6159-c285-40d5-9f48-34be24804579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                           headline  \\\n",
              "0           2  Agilent Technologies Announces Pricing of $5……...   \n",
              "1           3  Agilent (A) Gears Up for Q2 Earnings: What's i...   \n",
              "2           4  J.P. Morgan Asset Management Announces Liquida...   \n",
              "3           5  Pershing Square Capital Management, L.P. Buys ...   \n",
              "4           6  Agilent Awards Trilogy Sciences with a Golden ...   \n",
              "\n",
              "                                                 url  publisher  \\\n",
              "0  http://www.gurufocus.com/news/1153187/agilent-...  GuruFocus   \n",
              "1  http://www.zacks.com/stock/news/931205/agilent...      Zacks   \n",
              "2  http://www.gurufocus.com/news/1138923/jp-morga...  GuruFocus   \n",
              "3  http://www.gurufocus.com/news/1138704/pershing...  GuruFocus   \n",
              "4  http://www.gurufocus.com/news/1134012/agilent-...  GuruFocus   \n",
              "\n",
              "                  date stock  \n",
              "0  2020-06-01 00:00:00     A  \n",
              "1  2020-05-18 00:00:00     A  \n",
              "2  2020-05-15 00:00:00     A  \n",
              "3  2020-05-15 00:00:00     A  \n",
              "4  2020-05-12 00:00:00     A  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13f75160-dba0-4bc1-9400-4e38de991582\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>headline</th>\n",
              "      <th>url</th>\n",
              "      <th>publisher</th>\n",
              "      <th>date</th>\n",
              "      <th>stock</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>Agilent Technologies Announces Pricing of $5……...</td>\n",
              "      <td>http://www.gurufocus.com/news/1153187/agilent-...</td>\n",
              "      <td>GuruFocus</td>\n",
              "      <td>2020-06-01 00:00:00</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>Agilent (A) Gears Up for Q2 Earnings: What's i...</td>\n",
              "      <td>http://www.zacks.com/stock/news/931205/agilent...</td>\n",
              "      <td>Zacks</td>\n",
              "      <td>2020-05-18 00:00:00</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>J.P. Morgan Asset Management Announces Liquida...</td>\n",
              "      <td>http://www.gurufocus.com/news/1138923/jp-morga...</td>\n",
              "      <td>GuruFocus</td>\n",
              "      <td>2020-05-15 00:00:00</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>Pershing Square Capital Management, L.P. Buys ...</td>\n",
              "      <td>http://www.gurufocus.com/news/1138704/pershing...</td>\n",
              "      <td>GuruFocus</td>\n",
              "      <td>2020-05-15 00:00:00</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>Agilent Awards Trilogy Sciences with a Golden ...</td>\n",
              "      <td>http://www.gurufocus.com/news/1134012/agilent-...</td>\n",
              "      <td>GuruFocus</td>\n",
              "      <td>2020-05-12 00:00:00</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13f75160-dba0-4bc1-9400-4e38de991582')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-13f75160-dba0-4bc1-9400-4e38de991582 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-13f75160-dba0-4bc1-9400-4e38de991582');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.loc[(data['date'] <= '2019-12-31') & (data['date'] >= '2019-01-01')]\n",
        "\n",
        "import re\n",
        "from sklearn import feature_extraction \n",
        "stop_words = feature_extraction.text.ENGLISH_STOP_WORDS\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import nltk \n",
        "nltk.download('words')\n",
        "words = set(nltk.corpus.words.words())\n",
        "\n",
        "def preprocess(text):\n",
        "  text = text.lower() #lowercase\n",
        "  text = re.sub(r'[^\\w\\s]', '', text) #remove punctuations\n",
        "  text = re.sub(r'\\d+', '', text) #remove numbers\n",
        "  text = \" \".join(text.split()) #stripWhitespace\n",
        "  text = text.split()\n",
        "  text = [x for x in text if x not in stop_words] #remove stopwords\n",
        "  text = [x for x in text if x not in [\"stock\", \"stocks\",\"q\", \"buy\",\"market\",\"buys\"]] #remove task specific stopwords\n",
        "  text = \" \".join(text)\n",
        "  # stemmer_ps = PorterStemmer()  \n",
        "  # text = [stemmer_ps.stem(word) for word in text.split()] #stemming\n",
        "  # text = \" \".join(text)\n",
        "  # lemmatizer = WordNetLemmatizer()\n",
        "  # text = [lemmatizer.lemmatize(word) for word in text.split()]  #lemmatization\n",
        "  # text = \" \".join(text)\n",
        "  return(text)\n",
        "\n",
        "\n",
        "data['headline_processed']=data['headline'].apply(lambda x:preprocess(str(x)))\n",
        "data['headline_processed']=data['headline_processed'].apply(lambda x:x.split())\n",
        "\n",
        "from gensim import corpora\n",
        "dictionary = corpora.Dictionary(data['headline_processed'])\n",
        "dictionary.filter_extremes(no_below = 100, keep_tokens=['medicine','medical','increase','decrease'])\n",
        "data['headline_ids']=data['headline_processed'].apply(lambda x:dictionary.doc2bow(x))\n",
        "from gensim import models\n",
        "num_topics=10\n",
        "ldamodel = models.ldamodel.LdaModel(data['headline_ids'], num_topics = num_topics, id2word=dictionary, passes=5, random_state=100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOYBP-Sb8v7z",
        "outputId": "aacf793e-379b-452b-cc21-8d981d06d2e8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topics = ldamodel.print_topics(num_words=10)\n",
        "for topic in topics:\n",
        "    print(topic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bgsg8iGgJr1Z",
        "outputId": "c90aeaae-ea72-4f9d-d8af-c6b9e86de757"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.074*\"dividend\" + 0.030*\"declares\" + 0.021*\"bond\" + 0.021*\"yield\" + 0.019*\"investors\" + 0.017*\"high\" + 0.016*\"march\" + 0.016*\"class\" + 0.016*\"action\" + 0.016*\"reminds\"')\n",
            "(1, '0.125*\"earnings\" + 0.050*\"estimates\" + 0.038*\"beat\" + 0.035*\"etfs\" + 0.032*\"sales\" + 0.027*\"retail\" + 0.025*\"revenues\" + 0.021*\"outlook\" + 0.018*\"preview\" + 0.018*\"expected\"')\n",
            "(2, '0.077*\"beats\" + 0.072*\"revenue\" + 0.043*\"misses\" + 0.034*\"eps\" + 0.024*\"day\" + 0.019*\"conference\" + 0.019*\"lower\" + 0.019*\"systems\" + 0.019*\"economic\" + 0.019*\"bull\"')\n",
            "(3, '0.062*\"watch\" + 0.038*\"fund\" + 0.029*\"podcast\" + 0.027*\"best\" + 0.027*\"big\" + 0.024*\"shares\" + 0.019*\"natural\" + 0.017*\"rates\" + 0.015*\"momentum\" + 0.015*\"likely\"')\n",
            "(4, '0.043*\"zumiez\" + 0.035*\"energy\" + 0.028*\"gold\" + 0.022*\"gainers\" + 0.020*\"volatility\" + 0.020*\"losers\" + 0.020*\"tech\" + 0.018*\"sector\" + 0.018*\"consumer\" + 0.016*\"silver\"')\n",
            "(5, '0.052*\"portfolio\" + 0.049*\"update\" + 0.049*\"trade\" + 0.039*\"growth\" + 0.038*\"value\" + 0.025*\"investors\" + 0.019*\"right\" + 0.018*\"war\" + 0.016*\"vs\" + 0.015*\"better\"')\n",
            "(6, '0.062*\"week\" + 0.041*\"china\" + 0.037*\"report\" + 0.029*\"earnings\" + 0.027*\"weekly\" + 0.017*\"fed\" + 0.017*\"highlights\" + 0.017*\"street\" + 0.017*\"whats\" + 0.016*\"dividend\"')\n",
            "(7, '0.036*\"etf\" + 0.031*\"llc\" + 0.029*\"corp\" + 0.027*\"management\" + 0.027*\"oil\" + 0.025*\"capital\" + 0.023*\"sp\" + 0.022*\"new\" + 0.019*\"sells\" + 0.017*\"ishares\"')\n",
            "(8, '0.033*\"markets\" + 0.023*\"gains\" + 0.022*\"year\" + 0.022*\"deal\" + 0.017*\"reits\" + 0.017*\"real\" + 0.015*\"prices\" + 0.014*\"new\" + 0.014*\"global\" + 0.013*\"rally\"')\n",
            "(9, '0.124*\"earnings\" + 0.096*\"results\" + 0.053*\"ceo\" + 0.048*\"transcript\" + 0.028*\"notable\" + 0.019*\"reports\" + 0.018*\"financial\" + 0.018*\"heres\" + 0.017*\"close\" + 0.013*\"holdings\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2TxeGwLyyM4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import models\n",
        "ldamodel.save('model_beforeCovid.lda')"
      ],
      "metadata": {
        "id": "ypupmg0lOvII"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# covid-stage1\n",
        "data = pd.read_csv('raw_partner_headlines.csv')\n",
        "data = data.loc[(data['date'] >= '2020-01-01') & (data['date'] <= '2020-03-31')]\n",
        "\n",
        "import re\n",
        "from sklearn import feature_extraction \n",
        "stop_words = feature_extraction.text.ENGLISH_STOP_WORDS\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import nltk \n",
        "nltk.download('words')\n",
        "words = set(nltk.corpus.words.words())\n",
        "\n",
        "def preprocess(text):\n",
        "  text = text.lower() #lowercase\n",
        "  text = re.sub(r'[^\\w\\s]', '', text) #remove punctuations\n",
        "  text = re.sub(r'\\d+', '', text) #remove numbers\n",
        "  text = \" \".join(text.split()) #stripWhitespace\n",
        "  text = text.split()\n",
        "  text = [x for x in text if x not in stop_words] #remove stopwords\n",
        "  text = [x for x in text if x not in [\"stock\", \"stocks\",\"q\", \"buy\",\"market\",\"buys\",\"llc\",\"corp\",\"quarter\",\"report\",\"sp\",\"spdr\",\"year\",\"yy\",\"lp\",\"etfs\",\"new\"]] #remove task specific stopwords\n",
        "  text = \" \".join(text)\n",
        "  # stemmer_ps = PorterStemmer()  \n",
        "  # text = [stemmer_ps.stem(word) for word in text.split()] #stemming\n",
        "  # text = \" \".join(text)\n",
        "  # lemmatizer = WordNetLemmatizer()\n",
        "  # text = [lemmatizer.lemmatize(word) for word in text.split()]  #lemmatization\n",
        "  # text = \" \".join(text)\n",
        "  return(text)\n",
        "\n",
        "\n",
        "data['headline_processed']=data['headline'].apply(lambda x:preprocess(str(x)))\n",
        "data['headline_processed']=data['headline_processed'].apply(lambda x:x.split())\n",
        "\n",
        "from gensim import corpora\n",
        "dictionary = corpora.Dictionary(data['headline_processed'])\n",
        "dictionary.filter_extremes(no_below = 100, keep_tokens=['medicine','medical','increase','decrease'])\n",
        "data['headline_ids']=data['headline_processed'].apply(lambda x:dictionary.doc2bow(x))\n",
        "from gensim import models\n",
        "num_topics=20\n",
        "ldamodel_earlystage = models.ldamodel.LdaModel(data['headline_ids'], num_topics = num_topics, id2word=dictionary, passes=5, random_state=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-0MZr8JO-6g",
        "outputId": "ab2e5f17-5f7b-4c17-f101-1afd7f915960"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topics = ldamodel_earlystage.print_topics(num_words=10)\n",
        "for topic in topics:\n",
        "    print(topic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xxHXZ0xQV5A",
        "outputId": "17cea08a-f454-49e9-ae97-54cb3070489c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.118*\"rating\" + 0.054*\"watch\" + 0.053*\"key\" + 0.051*\"high\" + 0.050*\"rs\" + 0.050*\"rise\" + 0.047*\"hits\" + 0.039*\"technical\" + 0.037*\"ibd\" + 0.036*\"trading\"')\n",
            "(1, '0.136*\"global\" + 0.132*\"growth\" + 0.093*\"size\" + 0.086*\"share\" + 0.072*\"industry\" + 0.043*\"analysis\" + 0.041*\"trends\" + 0.034*\"business\" + 0.026*\"research\" + 0.025*\"key\"')\n",
            "(2, '0.120*\"review\" + 0.101*\"equity\" + 0.085*\"players\" + 0.077*\"hold\" + 0.061*\"tiffany\" + 0.057*\"g\" + 0.057*\"pdf\" + 0.043*\"outbreak\" + 0.042*\"solar\" + 0.040*\"picks\"')\n",
            "(3, '0.185*\"announces\" + 0.099*\"dow\" + 0.069*\"jones\" + 0.068*\"companies\" + 0.057*\"industrial\" + 0.050*\"shareholders\" + 0.034*\"filing\" + 0.034*\"deal\" + 0.031*\"limited\" + 0.030*\"news\"')\n",
            "(4, '0.150*\"ishares\" + 0.105*\"etf\" + 0.074*\"msci\" + 0.068*\"shares\" + 0.060*\"core\" + 0.042*\"ceo\" + 0.040*\"sold\" + 0.034*\"emerging\" + 0.034*\"markets\" + 0.029*\"russell\"')\n",
            "(5, '0.131*\"partners\" + 0.096*\"health\" + 0.094*\"gold\" + 0.059*\"care\" + 0.053*\"higher\" + 0.049*\"heres\" + 0.043*\"brands\" + 0.040*\"solutions\" + 0.037*\"edge\" + 0.034*\"focus\"')\n",
            "(6, '0.122*\"strength\" + 0.104*\"relative\" + 0.073*\"results\" + 0.064*\"fourth\" + 0.064*\"rising\" + 0.060*\"price\" + 0.052*\"shows\" + 0.041*\"low\" + 0.038*\"financial\" + 0.035*\"upgrades\"')\n",
            "(7, '0.099*\"trust\" + 0.071*\"conference\" + 0.065*\"announces\" + 0.053*\"million\" + 0.044*\"realty\" + 0.043*\"properties\" + 0.037*\"healthcare\" + 0.036*\"american\" + 0.035*\"digital\" + 0.032*\"board\"')\n",
            "(8, '0.328*\"earnings\" + 0.175*\"estimates\" + 0.082*\"revenues\" + 0.079*\"beat\" + 0.035*\"miss\" + 0.030*\"revenue\" + 0.027*\"rebound\" + 0.020*\"include\" + 0.019*\"loss\" + 0.018*\"featured\"')\n",
            "(9, '0.088*\"company\" + 0.058*\"fiscal\" + 0.051*\"december\" + 0.050*\"files\" + 0.050*\"k\" + 0.049*\"highlights\" + 0.047*\"bristolmyers\" + 0.045*\"zacks\" + 0.044*\"ended\" + 0.043*\"squibb\"')\n",
            "(10, '0.166*\"sector\" + 0.156*\"fund\" + 0.113*\"select\" + 0.052*\"index\" + 0.050*\"volatility\" + 0.042*\"consumer\" + 0.035*\"options\" + 0.033*\"feb\" + 0.033*\"thursday\" + 0.031*\"associates\"')\n",
            "(11, '0.099*\"week\" + 0.076*\"bank\" + 0.065*\"technology\" + 0.061*\"portfolio\" + 0.050*\"schwab\" + 0.048*\"invesco\" + 0.044*\"resources\" + 0.036*\"medical\" + 0.032*\"shortterm\" + 0.031*\"tech\"')\n",
            "(12, '0.224*\"energy\" + 0.087*\"march\" + 0.066*\"markets\" + 0.065*\"national\" + 0.047*\"bancorp\" + 0.042*\"strong\" + 0.041*\"monday\" + 0.041*\"tuesday\" + 0.030*\"retail\" + 0.028*\"usa\"')\n",
            "(13, '0.206*\"etf\" + 0.101*\"vanguard\" + 0.065*\"dividend\" + 0.056*\"ishares\" + 0.055*\"wealth\" + 0.051*\"bond\" + 0.036*\"management\" + 0.033*\"right\" + 0.033*\"trust\" + 0.030*\"total\"')\n",
            "(14, '0.109*\"investors\" + 0.098*\"alert\" + 0.077*\"shareholder\" + 0.068*\"reminds\" + 0.052*\"jan\" + 0.049*\"law\" + 0.038*\"rally\" + 0.038*\"llp\" + 0.037*\"class\" + 0.035*\"firm\"')\n",
            "(15, '0.150*\"value\" + 0.084*\"th\" + 0.083*\"february\" + 0.061*\"january\" + 0.055*\"income\" + 0.052*\"better\" + 0.048*\"ranked\" + 0.040*\"investors\" + 0.036*\"air\" + 0.036*\"vs\"')\n",
            "(16, '0.150*\"management\" + 0.122*\"capital\" + 0.114*\"sells\" + 0.088*\"group\" + 0.063*\"financial\" + 0.058*\"investment\" + 0.045*\"asset\" + 0.045*\"holdings\" + 0.031*\"truist\" + 0.030*\"international\"')\n",
            "(17, '0.096*\"oil\" + 0.076*\"update\" + 0.061*\"covid\" + 0.060*\"expected\" + 0.057*\"wednesday\" + 0.052*\"big\" + 0.051*\"charts\" + 0.045*\"industries\" + 0.044*\"provides\" + 0.044*\"gas\"')\n",
            "(18, '0.167*\"coronavirus\" + 0.110*\"earnings\" + 0.082*\"whats\" + 0.063*\"sales\" + 0.055*\"amid\" + 0.054*\"day\" + 0.036*\"data\" + 0.035*\"corporation\" + 0.034*\"store\" + 0.031*\"bear\"')\n",
            "(19, '0.090*\"earnings\" + 0.074*\"services\" + 0.067*\"ahead\" + 0.055*\"systems\" + 0.052*\"general\" + 0.043*\"know\" + 0.043*\"solid\" + 0.042*\"outlook\" + 0.039*\"best\" + 0.032*\"waste\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ldamodel_earlystage.save('model_earlystage.lda')"
      ],
      "metadata": {
        "id": "RpIIOX3RWRMG"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# covid-stage2\n",
        "data = pd.read_csv('raw_partner_headlines.csv')\n",
        "data = data.loc[(data['date'] > '2020-03-31') & (data['date'] <= '2020-06-31')]\n",
        "\n",
        "import re\n",
        "from sklearn import feature_extraction \n",
        "stop_words = feature_extraction.text.ENGLISH_STOP_WORDS\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import nltk \n",
        "nltk.download('words')\n",
        "words = set(nltk.corpus.words.words())\n",
        "\n",
        "import preprocessor as p\n",
        "# p.set_options(p.OPT.URL, p.OPT.EMOJI,p.OPT.MENTION,p.OPT.HASHTAG)\n",
        "p.set_options(p.OPT.URL, p.OPT.EMOJI,p.OPT.MENTION)\n",
        "\n",
        "def remove_html_tags(text):\n",
        "    \"\"\"Remove html tags from a string\"\"\"\n",
        "    import re\n",
        "    clean = re.compile('<.*?>')\n",
        "    return re.sub(clean, '', text)\n",
        "\n",
        "def preprocess(text):\n",
        "  text = text.lower() #lowercase\n",
        "  text = p.clean(text)\n",
        "  text = remove_html_tags(text)\n",
        "  # text = \" \".join(w for w in nltk.wordpunct_tokenize(text) if w.lower() in words or not w.isalpha()) #non-English\n",
        "  text = re.sub(r'[^\\w\\s]', '', text) #remove punctuations\n",
        "  text = re.sub(r'\\d+', '', text) #remove numbers\n",
        "  text = \" \".join(text.split()) #stripWhitespace\n",
        "  text = text.split()\n",
        "  text = [x for x in text if x not in stop_words] #remove stopwords\n",
        "  text = [x for x in text if x not in ['stock','stocks','covid','report','corp','llc','ishares','etf','spdr','sf','msci','amid']] #remove task specific stopwords\n",
        "  text = [x for x in text if len(x)>2]\n",
        "  text = \" \".join(text)\n",
        "  # stemmer_ps = PorterStemmer()  \n",
        "  # text = [stemmer_ps.stem(word) for word in text.split()] #stemming\n",
        "  # text = \" \".join(text)\n",
        "  # lemmatizer = WordNetLemmatizer()\n",
        "  # text = [lemmatizer.lemmatize(word) for word in text.split()]  #lemmatization\n",
        "  # text = \" \".join(text)\n",
        "  return(text)\n",
        "\n",
        "\n",
        "data['headline_processed']=data['headline'].apply(lambda x:preprocess(str(x)))\n",
        "data['headline_processed']=data['headline_processed'].apply(lambda x:x.split())\n",
        "\n",
        "from gensim import corpora\n",
        "dictionary = corpora.Dictionary(data['headline_processed'])\n",
        "dictionary.filter_extremes(no_below = 100, keep_tokens=['medicine','medical','increase','decrease'])\n",
        "data['headline_ids']=data['headline_processed'].apply(lambda x:dictionary.doc2bow(x))\n",
        "from gensim import models\n",
        "num_topics=20\n",
        "ldamodel_third = models.ldamodel.LdaModel(data['headline_ids'], num_topics = num_topics, id2word=dictionary, passes=5, random_state=100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYf5CcYvWaqG",
        "outputId": "ef4e2022-07fe-4886-824d-d18dfd62805d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topics = ldamodel_third.print_topics(num_words=10)\n",
        "for i in range(num_topics):\n",
        "    print(topics[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7-e4qHC9DYu",
        "outputId": "7c30180c-f9d3-4d7e-c8d0-75d037d808c2"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.151*\"international\" + 0.062*\"associates\" + 0.057*\"brands\" + 0.048*\"air\" + 0.045*\"proshares\" + 0.044*\"class\" + 0.044*\"medical\" + 0.043*\"technology\" + 0.041*\"products\" + 0.038*\"trading\"')\n",
            "(1, '0.083*\"strength\" + 0.067*\"relative\" + 0.066*\"rating\" + 0.050*\"united\" + 0.046*\"highlights\" + 0.044*\"zacks\" + 0.042*\"rising\" + 0.040*\"silver\" + 0.039*\"price\" + 0.038*\"analyst\"')\n",
            "(2, '0.121*\"shares\" + 0.086*\"dividend\" + 0.074*\"sold\" + 0.073*\"midcap\" + 0.071*\"million\" + 0.065*\"ceo\" + 0.043*\"point\" + 0.040*\"president\" + 0.037*\"pharmaceuticals\" + 0.035*\"royal\"')\n",
            "(3, '0.267*\"market\" + 0.118*\"global\" + 0.090*\"april\" + 0.088*\"growth\" + 0.051*\"thursday\" + 0.039*\"disney\" + 0.038*\"walt\" + 0.034*\"key\" + 0.032*\"monday\" + 0.030*\"equity\"')\n",
            "(4, '0.149*\"sector\" + 0.122*\"select\" + 0.113*\"fund\" + 0.095*\"buys\" + 0.077*\"services\" + 0.042*\"advisory\" + 0.040*\"financial\" + 0.031*\"edge\" + 0.026*\"usa\" + 0.018*\"research\"')\n",
            "(5, '0.310*\"earnings\" + 0.191*\"estimates\" + 0.086*\"revenues\" + 0.078*\"beat\" + 0.046*\"sales\" + 0.045*\"miss\" + 0.039*\"revenue\" + 0.038*\"low\" + 0.022*\"view\" + 0.020*\"beats\"')\n",
            "(6, '0.167*\"earnings\" + 0.083*\"decline\" + 0.065*\"expected\" + 0.058*\"bank\" + 0.054*\"tech\" + 0.044*\"preview\" + 0.043*\"berkshire\" + 0.041*\"therapeutics\" + 0.041*\"rise\" + 0.039*\"look\"')\n",
            "(7, '0.211*\"coronavirus\" + 0.190*\"value\" + 0.132*\"buy\" + 0.039*\"right\" + 0.038*\"ranked\" + 0.037*\"crisis\" + 0.034*\"performance\" + 0.032*\"companies\" + 0.028*\"woes\" + 0.027*\"healthcare\"')\n",
            "(8, '0.178*\"vanguard\" + 0.161*\"buys\" + 0.063*\"core\" + 0.051*\"wealth\" + 0.042*\"total\" + 0.035*\"schwab\" + 0.035*\"advisors\" + 0.032*\"management\" + 0.028*\"ftse\" + 0.025*\"financial\"')\n",
            "(9, '0.097*\"week\" + 0.094*\"oil\" + 0.067*\"tuesday\" + 0.049*\"market\" + 0.049*\"april\" + 0.048*\"wednesday\" + 0.047*\"gains\" + 0.044*\"firm\" + 0.043*\"watch\" + 0.042*\"law\"')\n",
            "(10, '0.252*\"energy\" + 0.096*\"dow\" + 0.083*\"rally\" + 0.069*\"jones\" + 0.061*\"technologies\" + 0.055*\"big\" + 0.048*\"higher\" + 0.047*\"industrial\" + 0.033*\"momentum\" + 0.032*\"points\"')\n",
            "(11, '0.234*\"buys\" + 0.121*\"management\" + 0.117*\"capital\" + 0.108*\"sells\" + 0.045*\"asset\" + 0.036*\"group\" + 0.031*\"holdings\" + 0.027*\"financial\" + 0.021*\"investment\" + 0.020*\"plc\"')\n",
            "(12, '0.162*\"year\" + 0.139*\"etfs\" + 0.094*\"alert\" + 0.070*\"shareholder\" + 0.058*\"general\" + 0.053*\"reminds\" + 0.041*\"investors\" + 0.036*\"johnson\" + 0.035*\"retail\" + 0.033*\"deadline\"')\n",
            "(13, '0.228*\"earnings\" + 0.115*\"whats\" + 0.082*\"ahead\" + 0.059*\"store\" + 0.041*\"march\" + 0.041*\"cards\" + 0.040*\"season\" + 0.036*\"post\" + 0.031*\"real\" + 0.031*\"today\"')\n",
            "(14, '0.140*\"buys\" + 0.128*\"trust\" + 0.076*\"bond\" + 0.070*\"short\" + 0.058*\"treasury\" + 0.041*\"income\" + 0.039*\"fund\" + 0.035*\"qqq\" + 0.032*\"powershares\" + 0.032*\"management\"')\n",
            "(15, '0.167*\"gold\" + 0.147*\"new\" + 0.086*\"reports\" + 0.055*\"resources\" + 0.051*\"loss\" + 0.051*\"strong\" + 0.046*\"data\" + 0.035*\"pacific\" + 0.034*\"gas\" + 0.030*\"sell\"')\n",
            "(16, '0.120*\"buys\" + 0.108*\"investment\" + 0.067*\"health\" + 0.059*\"russell\" + 0.057*\"partners\" + 0.051*\"high\" + 0.044*\"company\" + 0.034*\"yield\" + 0.034*\"amazon\" + 0.034*\"care\"')\n",
            "(17, '0.105*\"quarter\" + 0.085*\"results\" + 0.076*\"announces\" + 0.069*\"financial\" + 0.060*\"conference\" + 0.059*\"annual\" + 0.051*\"corporation\" + 0.045*\"meeting\" + 0.033*\"virtual\" + 0.033*\"earnings\"')\n",
            "(18, '0.230*\"announces\" + 0.072*\"shareholders\" + 0.064*\"senior\" + 0.049*\"offering\" + 0.045*\"insurance\" + 0.043*\"notes\" + 0.042*\"invest\" + 0.040*\"utilities\" + 0.038*\"million\" + 0.035*\"outlook\"')\n",
            "(19, '0.092*\"investors\" + 0.071*\"american\" + 0.069*\"update\" + 0.068*\"microsoft\" + 0.063*\"national\" + 0.058*\"business\" + 0.050*\"systems\" + 0.047*\"provides\" + 0.031*\"solutions\" + 0.030*\"home\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ldamodel_third.save('model_secondstage.lda')"
      ],
      "metadata": {
        "id": "Yboi2kE9CCkV"
      },
      "execution_count": 40,
      "outputs": []
    }
  ]
}